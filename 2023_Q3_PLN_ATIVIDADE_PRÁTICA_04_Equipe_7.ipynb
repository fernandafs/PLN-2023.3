{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fernandafs/PLN-2023.3-Equipe-7/blob/main/2023_Q3_PLN_ATIVIDADE_PR%C3%81TICA_04_Equipe_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6QILOdpOjwv"
      },
      "source": [
        "# **Processamento de Linguagem Natural [2023.Q3]**\n",
        "Prof. Alexandre Donizeti Alves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m67OOx9MX_3"
      },
      "source": [
        "### **ATIVIDADE PRÁTICA 04 [Uso da API da OpenAI com técnicas de PLN]**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Gk0nHKabBT-"
      },
      "source": [
        "A **ATIVIDADE PRÁTICA 04** deve ser feita utilizando o **Google Colab** com uma conta sua vinculada ao Gmail. O link do seu notebook, armazenado no Google Drive, além do link de um repositório no GitHub e os principais resultados da atividade, devem ser enviados usando o seguinte formulário:\n",
        "\n",
        "> https://forms.gle/GzwCq3R7ExtE9g9a8\n",
        "\n",
        "\n",
        "**IMPORTANTE**: A submissão deve ser feita até o dia 20/11 (segunda-feira) APENAS POR UM INTEGRANTE DA EQUIPE, até às 23h59. Por favor, lembre-se de dar permissão de ACESSO IRRESTRITO para o professor da disciplina de PLN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7hJlilKM485"
      },
      "source": [
        "### **EQUIPE**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**POR FAVOR, PREENCHER OS INTEGRANDES DA SUA EQUIPE:**\n",
        "\n",
        "\n",
        "**Integrante 01:**\n",
        "\n",
        "- Fernanda Felix da Silva RA: 11201921613\n",
        "\n",
        "**Integrante 02:**\n",
        "\n",
        "- Ricardo Juniti Kawai RA: 11202021571\n",
        "\n",
        "**Integrante 03:**\n",
        "\n",
        "- Samuel Brito da Silva RA: 11201810515"
      ],
      "metadata": {
        "id": "tnIArN0QY-Ek"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **LIVRO**\n",
        "---"
      ],
      "metadata": {
        "id": "6yExhaebs-nD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Processamento de Linguagem Natural - Conceitos, Técnicas e Aplicações em Português.`\n",
        "\n",
        ">\n",
        "\n",
        "Disponível gratuitamente em:\n",
        "  \n",
        "  > https://brasileiraspln.com/livro-pln/1a-edicao/.\n",
        "\n",
        "\n",
        "**POR FAVOR, PREENCHER OS CAPITULOS SELECIONADOS PARA A SUA EQUIPE:**\n",
        "\n",
        "`Primeiro capítulo: `\n",
        "\n",
        "- Cápitulo 7 (Link): https://brasileiraspln.com/livro-pln/1a-edicao/parte4/cap7/cap7.html\n",
        "\n",
        "\n",
        "`Segundo capítulo:`\n",
        "\n",
        "- Cápitulo 19 (Link): https://brasileiraspln.com/livro-pln/1a-edicao/parte8/cap19/cap19.html\n",
        "\n"
      ],
      "metadata": {
        "id": "DjJM_qhEZRy6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtjgWQRzNphL"
      },
      "source": [
        "### **DESCRIÇÃO**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementar um `notebook` no `Google Colab` que faça uso da **API da OpenAI** aplicando, no mínimo, 3 técnicas de PLN. As técnicas devem ser aplicadas nos 2 (DOIS) capítulos do livro **Processamento de Linguagem Natural - Conceitos, Técnicas e Aplicações em Português**.\n",
        "\n",
        ">\n",
        "\n",
        "**RESTRIÇÃO**: É obrigatório usar o *endpoint* \"*`Chat Completions`*\".\n",
        "\n",
        ">\n",
        "\n",
        "As seguintes técnicas de PLN podem ser usadas:\n",
        "\n",
        "*   Correção Gramatical\n",
        "*   Classificação de Textos\n",
        "*   Análise de Sentimentos\n",
        "*   Detecção de Emoções\n",
        "*   Extração de Palavras-chave\n",
        "*   Tradução de Textos\n",
        "*   Sumarização de Textos\n",
        "*   **Similaridade de Textos**\n",
        "*   **Reconhecimento de Entidades Nomeadas**\n",
        "*   **Sistemas de Perguntas e Respostas**\n",
        "\n",
        ">\n",
        "\n",
        "Os capítulos devem ser os mesmos selecionados na **ATIVIDADE PRÁTICA 02**. Para consultar os capítulos, considere a seguinte planilha:\n",
        "\n",
        ">\n",
        "\n",
        "> https://docs.google.com/spreadsheets/d/1ZutzQ3v1OJgsgzCvCwxXlRIQ3ChXNlHNvB63JQvYsbo/edit?usp=sharing\n",
        "\n",
        ">\n",
        ">\n",
        "\n",
        "**IMPORTANTE:** É obrigatório usar o e-mail da UFABC. Não é permitido alterar os capítulos já selecionados.\n",
        "\n"
      ],
      "metadata": {
        "id": "fXTwkiiGs2BV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CRITÉRIOS DE AVALIAÇÃO**\n",
        "---\n"
      ],
      "metadata": {
        "id": "gWsBYQNtxmum"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Serão considerados como critérios de avaliação as técnicas usadas e a criatividade envolvida na aplicação das mesmas.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5iHdx4BXYruQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **IMPLEMENTAÇÃO**\n",
        "---"
      ],
      "metadata": {
        "id": "nw09lujGvfjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Passo 1.0 - Instalação do pacote Python da API da OpenAI\n",
        "\n",
        "!pip install openai==0.28.1"
      ],
      "metadata": {
        "id": "AwyHaQQKVCJs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "263a03bd-2235-4d36-9f37-787fc1a177c2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai==0.28.1 in /usr/local/lib/python3.10/dist-packages (0.28.1)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (3.8.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Passo 1.1 - Import das bibliotecas utilizadas\n",
        "\n",
        "import openai\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "from google.colab import files\n",
        "import random"
      ],
      "metadata": {
        "id": "3kW4mKGmQZUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Passo 1.2 - Configuração da chave de acesso da API a partir do upload de um arquivo de texto\n",
        "\n",
        "from getpass import getpass\n",
        "\n",
        "openai.api_key = getpass()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H74OOIQ5QdHn",
        "outputId": "1188de2a-38d5-421d-fcdb-201ff6b3a50b"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Passo 1.3 - Extração do conteúdo dos capítulos escolhidos + implantação das técnicas de PLN\n",
        "\n",
        "def extrai_texto(link, user_list):\n",
        "\n",
        "  response = requests.get(link, headers={'User-Agent': random.choice(user_list)})\n",
        "\n",
        "  # Valida se a solicitação foi bem sucedida e caso seja, transforma retira os\n",
        "  # paragráfos de texto dentro da página e também inicializa um array para\n",
        "  #guardar os erros.\n",
        "  if response.status_code == 200:\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    paragrafos = soup.find_all('p')\n",
        "\n",
        "\n",
        "    # Retirada de URL das validações\n",
        "    padrao_url = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
        "\n",
        "    texto_capitulo = []\n",
        "    paragrafos_coletados = 0\n",
        "\n",
        "    # Passo 1.3.1 - Extração de conteúdo dos arquivos\n",
        "    for paragrafo in paragrafos:\n",
        "      texto = paragrafo.get_text()\n",
        "      texto_sem_urls = re.sub(padrao_url, '', texto)\n",
        "      texto_capitulo.append(texto_sem_urls)\n",
        "\n",
        "      paragrafos_coletados += 1\n",
        "      if paragrafos_coletados >= 35 and link == 'https://brasileiraspln.com/livro-pln/1a-edicao/parte8/cap19/cap19.html':\n",
        "        break  # Para de coletar parágrafos após atingir a quantidade desejada (necessário devido a API não conseguir ler o texto inteiro)\n",
        "      elif paragrafos_coletados >= 70:\n",
        "        break # Para de coletar parágrafos após atingir a quantidade desejada (necessário devido a API não conseguir ler o texto inteiro)\n",
        "\n",
        "\n",
        "    texto_completo = '\\n'.join(texto_capitulo)\n",
        "    # Passo 1.3.2 - Implementação das técnicas de PLN\n",
        "\n",
        "    endpoint = \"https://api.openai.com/v1/chat/completions\"\n",
        "\n",
        "    # 1.3.2.1 Correção Gramatical:\n",
        "    mensagem_sistema = 'Corrija os erros gramaticais no texto.'\n",
        "    mensagem_assistente = 'Mostre a quantidade de palavras/orações corrigidas além de escrever a frase correta.'\n",
        "\n",
        "    parametros = {\n",
        "      \"model\": \"gpt-3.5-turbo-0613\",\n",
        "      \"messages\": [\n",
        "          {\"role\": \"system\", \"content\": mensagem_sistema},\n",
        "          {\"role\": \"user\", \"content\": texto_completo},\n",
        "          {\"role\": \"assistant\", \"content\": mensagem_assistente}]\n",
        "    }\n",
        "    headers = {\n",
        "      \"Content-Type\": \"application/json\",\n",
        "      \"Authorization\": f\"Bearer {openai.api_key}\"\n",
        "    }\n",
        "\n",
        "    resposta = requests.post(endpoint, json=parametros, headers=headers)\n",
        "    resultado = resposta.json()\n",
        "\n",
        "    print(\"Resultado Correção Gramatical:\")\n",
        "    print(resultado)\n",
        "\n",
        "    # 1.3.2.2 Sumarização do texto:\n",
        "    mensagem_sistema2 = 'Resuma o texto em poucas palavras.'\n",
        "    mensagem_assistente2 = 'Escreva o texto resumido e indique em quantos paragrafos a menos do original o resumo foi escrito.'\n",
        "\n",
        "    parametros = {\n",
        "      \"model\": \"gpt-3.5-turbo-0613\",\n",
        "      \"messages\": [\n",
        "          {\"role\": \"system\", \"content\": mensagem_sistema2},\n",
        "          {\"role\": \"user\", \"content\": texto_completo},\n",
        "          {\"role\": \"assistant\", \"content\": mensagem_assistente2}]\n",
        "    }\n",
        "    headers = {\n",
        "      \"Content-Type\": \"application/json\",\n",
        "      \"Authorization\": f\"Bearer {openai.api_key}\"\n",
        "    }\n",
        "\n",
        "    resposta2 = requests.post(endpoint, json=parametros, headers=headers)\n",
        "    resultado2 = resposta2.json()\n",
        "\n",
        "    print(\"Resultado Sumarização:\")\n",
        "    print(resultado2)\n",
        "\n",
        "    # 1.3.2.3 Detecção de palavras-chave:\n",
        "    mensagem_sistema3 = 'Gerar palavras-chave de cauda longa referentes ao texto que sejam as melhores para atrair o publico alvo: \"Alunos de PLN\".'\n",
        "    mensagem_assistente3 = 'Escreva as palavras-chave.'\n",
        "\n",
        "    parametros = {\n",
        "      \"model\": \"gpt-3.5-turbo-0613\",\n",
        "      \"messages\": [\n",
        "          {\"role\": \"system\", \"content\": mensagem_sistema3},\n",
        "          {\"role\": \"user\", \"content\": texto_completo},\n",
        "          {\"role\": \"assistant\", \"content\": mensagem_assistente3}]\n",
        "    }\n",
        "    headers = {\n",
        "      \"Content-Type\": \"application/json\",\n",
        "      \"Authorization\": f\"Bearer {openai.api_key}\"\n",
        "    }\n",
        "\n",
        "    resposta3 = requests.post(endpoint, json=parametros, headers=headers)\n",
        "    resultado3 = resposta3.json()\n",
        "\n",
        "    print(\"Resultado Palavras-chave:\")\n",
        "    print(resultado3)\n",
        "\n",
        "    # 1.3.2.4 Tradução para o inglês:\n",
        "    mensagem_sistema4 = 'Traduza o texto para o inglês, e resuma em poucas palavras.'\n",
        "    mensagem_assistente4 = 'Escreva o texto final.'\n",
        "\n",
        "    parametros = {\n",
        "      \"model\": \"gpt-3.5-turbo-0613\",\n",
        "      \"messages\": [\n",
        "          {\"role\": \"system\", \"content\": mensagem_sistema4},\n",
        "          {\"role\": \"user\", \"content\": texto_completo},\n",
        "          {\"role\": \"assistant\", \"content\": mensagem_assistente4}]\n",
        "    }\n",
        "    headers = {\n",
        "      \"Content-Type\": \"application/json\",\n",
        "      \"Authorization\": f\"Bearer {openai.api_key}\"\n",
        "    }\n",
        "\n",
        "    resposta4 = requests.post(endpoint, json=parametros, headers=headers)\n",
        "    resultado4 = resposta4.json()\n",
        "\n",
        "    print(\"Resultado Tradução inglês resumido:\")\n",
        "    print(resultado4)\n",
        "\n",
        "    # 1.3.2.5 Classificação de Textos:\n",
        "    mensagem_sistema5 = 'Classifique o texto de acordo com 3 categorias que são abordadas. Separe as 3 categorias por \";\".'\n",
        "    mensagem_assistente5 = 'Escreva as categorias do texto.'\n",
        "\n",
        "    parametros = {\n",
        "      \"model\": \"gpt-3.5-turbo-0613\",\n",
        "      \"messages\": [\n",
        "          {\"role\": \"system\", \"content\": mensagem_sistema5},\n",
        "          {\"role\": \"user\", \"content\": texto_completo},\n",
        "          {\"role\": \"assistant\", \"content\": mensagem_assistente5}]\n",
        "    }\n",
        "    headers = {\n",
        "      \"Content-Type\": \"application/json\",\n",
        "      \"Authorization\": f\"Bearer {openai.api_key}\"\n",
        "    }\n",
        "\n",
        "    resposta5 = requests.post(endpoint, json=parametros, headers=headers)\n",
        "    resultado5 = resposta5.json()\n",
        "\n",
        "    print(\"Resultado Classificação de Textos:\")\n",
        "    print(resultado5)\n",
        "  else:\n",
        "\n",
        "    print(f\"Não foi possível obter o conteúdo do link: {link}\")\n",
        "    return []\n",
        "links = [\n",
        "    \"https://brasileiraspln.com/livro-pln/1a-edicao/parte4/cap7/cap7.html\",\n",
        "    \"https://brasileiraspln.com/livro-pln/1a-edicao/parte8/cap19/cap19.html\"\n",
        "]\n",
        "\n",
        "user_agents_list = [\n",
        "    'Mozilla/5.0 (iPad; CPU OS 12_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Mobile/15E148',\n",
        "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.83 Safari/537.36',\n",
        "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.83 Safari/537.36'\n",
        "]\n",
        "\n",
        "# Perpassa por ambos os links chamando a função \"extrai_texto\" para obter seu conteúdo.\n",
        "for link in links:\n",
        "    print(f\"Extraindo capítulo: {link}\")\n",
        "    extrai_texto(link, user_agents_list)"
      ],
      "metadata": {
        "id": "RyUailD5vi9E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "814089fb-bda1-47a1-859d-7875976dc6b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraindo capítulo: https://brasileiraspln.com/livro-pln/1a-edicao/parte4/cap7/cap7.html\n",
            "Resultado Correção Gramatical:\n",
            "{'id': 'chatcmpl-8MjudwOWuFmWGhhF3NH9HljPThO5V', 'object': 'chat.completion', 'created': 1700430395, 'model': 'gpt-3.5-turbo-0613', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': 'Não é possível contar a quantidade de palavras/orações corrigidas sem ter acesso ao texto original e à correção completa. Porém, vou corrigir os erros gramaticais identificados no texto:\\n\\n1) \"Ferramenta que realiza essa tarefa é denominada parser\"\\n- \"A ferramenta que realiza essa tarefa é denominada parser\"\\n\\n2) \"em PLN, a análise computacional realizada no nível sintático é denominada parsing\"\\n- \"Em PLN, a análise computacional realizada no nível sintático é denominada parsing\"\\n\\n3) \"parsing parcial é conhecido como chunking\"\\n- \"O parsing parcial é conhecido como chunking\"\\n\\n4) \"No uso geral, os termos parsing e parser acabaram sendo adotados para se referir ao parsing completo\"\\n- \"No uso geral, os termos parsing e parser acabaram sendo adotados para se referir ao parsing completo.\"\\n\\n5) \"Tomando como exemplo o parsing de constituência\"\\n- \"Tomando o exemplo do parsing de constituência\"\\n\\n6) \"Como vemos na Figura 7.3, o chunking reconhece três unidades ou chunks\"\\n- \"Como vemos na Figura 7.3, o chunking reconhece três unidades ou chunks.\"\\n\\n7) \"O corpus Bosque é parte de um corpus maior\"\\n- \"O corpus Bosque faz parte de um corpus maior\"\\n\\n8) \"O corpus Bosque está integrado por sentenças extraídas dos corpora CETENFolha e CETEMPúblico\"\\n- \"O corpus Bosque é composto por sentenças extraídas dos corpora CETENFolha e CETEMPúblico\"\\n\\n9) \"mais recentemente, o corpus PetroGold foi disponibilizado\"\\n- \"Mais recentemente, o corpus PetroGold foi disponibilizado\"\\n\\n10) \"No escopo do projeto NLP2, desenvolvido pelo Centro de Inteligência Artificial\"\\n- \"No escopo do projeto NLP2, desenvolvido pelo Centro de Inteligência Artificial\"\\n\\n11) \"Por exemplo, Curupira é um analisador robusto de uso geral\"\\n- \"Por exemplo, Curupira é um analisador robusto de uso geral.\"\\n\\n12) \"Donatus é um projeto que consiste em ferramentas e gramáticas\"\\n- \"Donatus é um projeto que consiste em ferramentas e gramáticas.\"\\n\\n13) \"PassPort é uma ferramenta para análise de dependências de português\"\\n- \"PassPort é uma ferramenta para análise de dependências do português\"\\n\\n14) \"entre as bibliotecas que incluem parsing para língua portuguesa, podemos citar spaCy\"\\n- \"Entre as bibliotecas que incluem parsing para língua portuguesa, podemos cit'}, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 3489, 'completion_tokens': 609, 'total_tokens': 4098}}\n",
            "Resultado Sumarização:\n",
            "{'id': 'chatcmpl-8Mjw7PeYccz6l5EZXL8g8J3gATZIN', 'object': 'chat.completion', 'created': 1700430487, 'model': 'gpt-3.5-turbo-0613', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': 'A sintaxe é o nível de análise linguística que estuda a estrutura das sentenças. Existem dois tipos de parsing em PLN: parsing de constituência e parsing de dependência. O parsing pode ser completo, analisando toda a estrutura da sentença, ou parcial, identificando apenas constituintes delimitados. Existem diversas ferramentas e recursos para realizar a análise sintática em português, como os corpora anotados, os parsers Curupira, Donatus e PassPort, e as bibliotecas spaCy, Stanza e NLTK. Também existem ferramentas web, como o Parser LX e o Parser VISL. (Resumo em 1 parágrafo)'}, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 3494, 'completion_tokens': 159, 'total_tokens': 3653}}\n",
            "Resultado Palavras-chave:\n",
            "{'id': 'chatcmpl-8MjwJV3gUW5pio0olDhEuvLW1JlMH', 'object': 'chat.completion', 'created': 1700430499, 'model': 'gpt-3.5-turbo-0613', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': 'Parsers de PLN, análise sintática, parsing de constituência, parsing de dependência, parsing completo, parsing parcial, chunking, treebank, corpus anotado, Bosque, Floresta Sintá(c)tica, CINTIL, PetroGold, Porttinari, Veredas, Curupira, Donatus, PassPort, spaCy, Stanza, NLTK, Parser LX, Parser VISL.'}, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 3501, 'completion_tokens': 93, 'total_tokens': 3594}}\n",
            "Resultado Tradução inglês resumido:\n",
            "{'id': 'chatcmpl-8MjwWKUFwkhXxI77JW6Ia91HW2wDb', 'object': 'chat.completion', 'created': 1700430512, 'model': 'gpt-3.5-turbo-0613', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': 'Elisa Terumi Rubel Schneider \\nAdriana S Pagano \\nAna Clara S Pagano \\n26/09/2023\\nPDF\\nSyntax is the level of linguistic analysis in which we examine sentence structuring patterns. We analyze how words are organized into units that create meaning within the sentence. This involves considering the class of each word, its order in the sentence, and its relationship with other words. In natural language processing (NLP), the computational analysis performed at the syntactic level is called parsing, the tool that performs this task is called a parser, and the resource created through syntactic analysis is called a treebank.\\nIn this chapter, we will learn about types of parsing from a computational perspective, along with tools and resources available for processing Brazilian Portuguese.\\nThe parsing task consists of predicting the syntactic structure of a sentence given an unannotated input (raw) sentence. As we saw in Chapter 6, the objective of syntactic processing is to identify units (such as words, phrases, and clauses) in the sentence and establish grammatical relations between them to extract some type of information. These relations can be analyzed in terms of:\\nThus, depending on the type of syntactic analysis adopted, there are constituency parsers and dependency parsers.\\nBut there is an additional perspective under which we can characterize types of parsing and parsers: the scope or depth at which syntactic analysis is performed. In this sense, we can analyze sentences exhaustively until we obtain a complete analysis of their structure or we can perform a shallow analysis to obtain an analysis with minimal but relevant information for NLP tasks.\\nThe first type is called deep or complete parsing, and the second type is called shallow or partial parsing. However, it should be noted that in general usage, the terms parsing and parser have come to refer to complete parsing. On the other hand, partial parsing is known as chunking, and the tool is called a chunker, although chunking is one of several approaches to implementing partial parsing (Jurafsky; Martin, 2023).\\nBoth constituency parsing and dependency parsing can be performed in a complete or partial manner. Taking constituency parsing as an example, a complete or deep analysis extracts all the groupings and syntactic relations in a sentence. For example, given the sentence:\\nExample 7.1 \\nEmma Watson posted a photo with Daniel Radcliffe.\\nFigure 7.1 shows a tree diagram representation that illustrates the depth of the analysis.\\n\\nOn the other hand, a partial analysis extracts delimited constituents without establishing the hierarchy between them or how they are contained within each other.\\nFigure 7.2 illustrates the shallow, non-hierarchical analysis of partial parsing for Example 7.1.\\n\\nThe goal of partial parsing is to generate a shallow representation of the sentence structure that allows for faster processing of large volumes of text. It is generally implemented through tokenization of a sentence into words, identification of the part of speech (PoS), and segmentation into chunks. The concept of a chunk was proposed by Abney (1992) as a unit formed'}, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 3482, 'completion_tokens': 616, 'total_tokens': 4098}}\n",
            "Resultado Classificação de Textos:\n",
            "{'id': 'chatcmpl-8MjxpiSQOZLS0bQddIF5DekClYqg9', 'object': 'chat.completion', 'created': 1700430593, 'model': 'gpt-3.5-turbo-0613', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': 'Análise sintática; Recursos e ferramentas de PLN; Parsers e ferramentas disponíveis para análise sintática do português.'}, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 3492, 'completion_tokens': 34, 'total_tokens': 3526}}\n",
            "Extraindo capítulo: https://brasileiraspln.com/livro-pln/1a-edicao/parte8/cap19/cap19.html\n",
            "Resultado Correção Gramatical:\n",
            "{'id': 'chatcmpl-8MjxwjbUJiwRQn0TT9YeEdJGaBKgh', 'object': 'chat.completion', 'created': 1700430600, 'model': 'gpt-3.5-turbo-0613', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': 'Amanda Pontes Rassi \\nPriscilla de Abreu Lopes \\n26/09/2023\\nPDF\\nA Correção Automática de Redação (CAR) é uma das várias aplicações do PLN e pode ser definida como “o processo de avaliação e atribuição de nota em textos escritos em prosa, via programas computacionais” (Shermis; Burstein, 2013) [1].\\nA correção manual de redações é uma prática bastante antiga, mas esse processo feito de forma automática data da década de 60, em inglês, e é ainda mais recente para o português.\\nEm inglês, as áreas de Automated Essay Scoring (AES) e Automated Essay Evaluation (AEE) surgem como distintas, porém complementares e, às vezes, com alguma intersecção. A primeira tem como desafio a automatização de atribuição de nota para redação, enquanto a segunda está preocupada, também, em automatizar o retorno ou feedback para o aluno, colaborando para o processo de aprendizagem da escrita.\\nA AES costuma ser traduzida para o português como Avaliação Automática de Redação (AAR) (Bittencourt Jr., 2020; Da Silva Jr., 2021; Lima et al., 2023), enquanto a AEE está associada ao termo Correção Automática de Redação (CAR), apesar do falso cognato. Neste capítulo, adotamos o segundo, por entender que ele abarca as duas áreas AEE e AES, ou seja, trata-se de uma solução completa. Para que seja considerada como solução completa de CAR, a aplicação deve contemplar pelo menos três etapas básicas:\\nCada uma dessas etapas pode ser vista como uma aplicação independente no PLN. Por exemplo, existem várias ferramentas de auxílio à escrita, bem como corretores ortográficos e gramaticais, que executam exclusivamente a tarefa de identificação de desvios no texto; e isso constitui uma aplicação em si. Da mesma forma, a tarefa de dar um feedback com sugestões para o aluno é semelhante a outras aplicações de PLN que envolvem geração de linguagem natural (ou Natural Language Generation).\\nApesar de poderem figurar como ferramentas e/ou aplicações independentes, consideramos que a correção de redação, para ser entendida como uma solução completa do ponto de vista pedagógico, exige o cumprimento dessas três etapas, que serão bem detalhadas ao longo deste capítulo.\\nAntes de abordar cada uma das etapas, porém, faremos uma breve explicação sobre o objeto de estudo da CAR, que é a redação escolar, definindo e exemplificando os principais gêneros e tipos textuais, os critérios avaliados e alguns modelos brasileiros de correção de redação.\\nA redação escolar é considerada um gênero textual, mas também pode ser distribuída em'}, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 3420, 'completion_tokens': 678, 'total_tokens': 4098}}\n",
            "Resultado Sumarização:\n",
            "{'id': 'chatcmpl-8MjzQ1hqQU7bYKqLLqErdZYZ2Glin', 'object': 'chat.completion', 'created': 1700430692, 'model': 'gpt-3.5-turbo-0613', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': 'A correção automática de redação é uma aplicação do Processamento de Linguagem Natural (PLN) que avalia e atribui nota a textos escritos. Ela consiste em três etapas: identificação de desvios no texto, feedback para o aluno e geração de linguagem natural. A redação escolar pode ser de diferentes tipos e gêneros textuais, sendo avaliada quanto à linguagem, abordagem temática, adequação ao tipo e gênero textual, coerência e coesão. Existem vários modelos de correção de redação, como o Enem, Fuvest, Unesp e Unicamp. Cada modelo possui critérios e pesos específicos para a avaliação. (Resumo em 1 parágrafo)'}, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 3425, 'completion_tokens': 170, 'total_tokens': 3595}}\n",
            "Resultado Palavras-chave:\n",
            "{'id': 'chatcmpl-8MjzrB63v7IXuPLwX0NfhYOxiaSzm', 'object': 'chat.completion', 'created': 1700430719, 'model': 'gpt-3.5-turbo-0613', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': '- Correção Automática de Redação (CAR)\\n- PLN (Processamento de Linguagem Natural)\\n- Avaliação Automática de Redação (AAR)\\n- Correção Manual de Redações\\n- Redação Escolar\\n- Gênero Textual\\n- Tipo Textual\\n- Dissertação-Argumentativa\\n- Coesão e Coerência\\n- Norma Padrão da Língua Portuguesa\\n- Progressão Textual\\n- Abordagem Temática\\n- Proposta de Intervenção\\n- Enem\\n- Fuvest\\n- Unesp\\n- Unicamp\\n- Modelos de Correção\\n- Critérios de Avaliação\\n- Habilidades de Escrita\\n- Pensamento Crítico\\n- Expressão Escrita\\n- Desenvolvimento do Tema\\n- Organização do Texto'}, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 3432, 'completion_tokens': 184, 'total_tokens': 3616}}\n",
            "Resultado Tradução inglês resumido:\n",
            "{'id': 'chatcmpl-8Mk06VdDCYt7H2wruc4bky7i85rpY', 'object': 'chat.completion', 'created': 1700430734, 'model': 'gpt-3.5-turbo-0613', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': 'Automated Essay Correction (CAR) is a process that utilizes Natural Language Processing (NLP) to evaluate and grade written texts. It involves three basic stages: identification of errors, providing feedback to the student, and generating a final grade. CAR is commonly used in educational settings to assess writing skills and improve the learning process. Different models of correction exist, such as AES and AEE, which address automatic grading and feedback, respectively. CAR is considered a complete solution when it encompasses all three stages. Several criteria are evaluated in essay correction, including language proficiency, thematic development, adherence to genre and type, coherence and cohesion, and the appropriate use of language resources. Some examples of Brazilian models for essay correction include the Enem, Fuvest, Unesp, and Unicamp, each with their own specific evaluation criteria and scoring ranges.'}, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 3413, 'completion_tokens': 168, 'total_tokens': 3581}}\n",
            "Resultado Classificação de Textos:\n",
            "{'id': 'chatcmpl-8Mk0Tm3zDZxQkgalMEVOyyGwIGsCo', 'object': 'chat.completion', 'created': 1700430757, 'model': 'gpt-3.5-turbo-0613', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': '1) Correção Automática de Redação (CAR) e suas etapas;\\n2) Tipos e gêneros textuais na redação escolar;\\n3) Modelos de correção de redação.'}, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 3423, 'completion_tokens': 46, 'total_tokens': 3469}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pyUQi_bAhk_6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}